{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6aaee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 12:57:17 INFO mlflow.tracking.fluent: Experiment with name 'Exp 4 - ml models' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-s3-raj/248505974370810731', creation_time=1753700237894, experiment_id='248505974370810731', last_update_time=1753700237894, lifecycle_stage='active', name='Exp 4 - ml models', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "# Step 2: Set up the MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://ec2-16-16-185-18.eu-north-1.compute.amazonaws.com:5000/\")\n",
    "mlflow.set_experiment(\"Exp 4 - ml models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b1a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee7cc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reddit_preprocessing.csv').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e0bbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 12:57:59,244] A new study created in memory with name: no-name-f205f0a6-9628-4460-9869-190caeabee84\n",
      "[I 2025-07-28 13:00:23,326] Trial 0 finished with value: 0.7151234147006682 and parameters: {'n_estimators': 97, 'learning_rate': 0.05118864598972083, 'max_depth': 8}. Best is trial 0 with value: 0.7151234147006682.\n",
      "[I 2025-07-28 13:04:08,821] Trial 1 finished with value: 0.6616664393836084 and parameters: {'n_estimators': 211, 'learning_rate': 0.008265376035008815, 'max_depth': 8}. Best is trial 0 with value: 0.7151234147006682.\n",
      "[I 2025-07-28 13:04:57,952] Trial 2 finished with value: 0.5329333151506886 and parameters: {'n_estimators': 160, 'learning_rate': 0.00021852967338204155, 'max_depth': 4}. Best is trial 0 with value: 0.7151234147006682.\n",
      "[I 2025-07-28 13:06:09,118] Trial 3 finished with value: 0.6433928814946134 and parameters: {'n_estimators': 164, 'learning_rate': 0.01282896392413274, 'max_depth': 5}. Best is trial 0 with value: 0.7151234147006682.\n",
      "[I 2025-07-28 13:11:03,599] Trial 4 finished with value: 0.7170325923905632 and parameters: {'n_estimators': 166, 'learning_rate': 0.02444682202659183, 'max_depth': 10}. Best is trial 4 with value: 0.7170325923905632.\n",
      "[I 2025-07-28 13:17:47,820] Trial 5 finished with value: 0.6718941770080458 and parameters: {'n_estimators': 275, 'learning_rate': 0.00702658439492567, 'max_depth': 9}. Best is trial 4 with value: 0.7170325923905632.\n",
      "[I 2025-07-28 13:18:02,919] Trial 6 finished with value: 0.5341606436656212 and parameters: {'n_estimators': 66, 'learning_rate': 0.0028411963196040115, 'max_depth': 3}. Best is trial 4 with value: 0.7170325923905632.\n",
      "[I 2025-07-28 13:20:16,747] Trial 7 finished with value: 0.6459839083594708 and parameters: {'n_estimators': 270, 'learning_rate': 0.008180650323188099, 'max_depth': 5}. Best is trial 4 with value: 0.7170325923905632.\n",
      "[I 2025-07-28 13:24:18,411] Trial 8 finished with value: 0.6560752761489158 and parameters: {'n_estimators': 134, 'learning_rate': 0.007811978934672329, 'max_depth': 10}. Best is trial 4 with value: 0.7170325923905632.\n",
      "[I 2025-07-28 13:25:02,817] Trial 9 finished with value: 0.5344333833356062 and parameters: {'n_estimators': 126, 'learning_rate': 0.0007015936696938595, 'max_depth': 4}. Best is trial 4 with value: 0.7170325923905632.\n",
      "[I 2025-07-28 13:27:04,788] Trial 10 finished with value: 0.7908086731215055 and parameters: {'n_estimators': 220, 'learning_rate': 0.09700170780504117, 'max_depth': 7}. Best is trial 10 with value: 0.7908086731215055.\n",
      "[I 2025-07-28 13:29:06,084] Trial 11 finished with value: 0.7833083321969181 and parameters: {'n_estimators': 216, 'learning_rate': 0.08761272953100677, 'max_depth': 7}. Best is trial 10 with value: 0.7908086731215055.\n",
      "[I 2025-07-28 13:31:09,959] Trial 12 finished with value: 0.7831719623619255 and parameters: {'n_estimators': 214, 'learning_rate': 0.08728562688010919, 'max_depth': 7}. Best is trial 10 with value: 0.7908086731215055.\n",
      "[I 2025-07-28 13:33:06,307] Trial 13 finished with value: 0.782762852856948 and parameters: {'n_estimators': 224, 'learning_rate': 0.09627409821301962, 'max_depth': 6}. Best is trial 10 with value: 0.7908086731215055.\n",
      "[W 2025-07-28 13:34:29,821] Trial 14 failed with parameters: {'n_estimators': 239, 'learning_rate': 0.03236159056161548, 'max_depth': 7} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajratan/anaconda3/envs/restapi/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_37765/3190478224.py\", line 57, in objective_xgboost\n",
      "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rajratan/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/rajratan/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1682, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/rajratan/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/rajratan/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/training.py\", line 183, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/rajratan/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/core.py\", line 2247, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-28 13:34:29,923] Trial 14 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     70\u001b[39m     log_mlflow(\u001b[33m\"\u001b[39m\u001b[33mXGBoost\u001b[39m\u001b[33m\"\u001b[39m, best_model, X_train_vec, X_test_vec, y_train, y_test)\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Run the experiment for XGBoost\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mrun_optuna_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mrun_optuna_experiment\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_optuna_experiment\u001b[39m():\n\u001b[32m     62\u001b[39m     study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_xgboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# Get the best parameters and log only the best model\u001b[39;00m\n\u001b[32m     66\u001b[39m     best_params = study.best_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mobjective_xgboost\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     54\u001b[39m max_depth = trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m10\u001b[39m)\n\u001b[32m     56\u001b[39m model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y_test, \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m.predict(X_test_vec))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/sklearn.py:1682\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1660\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1661\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1662\u001b[39m )\n\u001b[32m   1663\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1664\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1665\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1679\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1680\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/restapi/lib/python3.11/site-packages/xgboost/core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
    "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
    "\n",
    "# Step 2: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "ngram_range = (1, 3)  # Trigram setting\n",
    "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "# Step 4: Train-test split before vectorization and resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
    "\n",
    "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Function to log results in MLflow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "\n",
    "# Step 6: Optuna objective function for XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "\n",
    "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
    "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
    "\n",
    "\n",
    "# Step 7: Run Optuna for XGBoost, log the best model only\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_xgboost, n_trials=30)\n",
    "\n",
    "    # Get the best parameters and log only the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
    "\n",
    "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
    "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "\n",
    "# Run the experiment for XGBoost\n",
    "run_optuna_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc3e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "restapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
